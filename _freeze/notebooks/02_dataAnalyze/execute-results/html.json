{
  "hash": "f6b83b4d81710b00a0b9ecf675010a97",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"02_dataAnalyze\"\nauthor: \"Munkhtsetseg\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\nLibrary\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ggplot2)\n```\n:::\n\n\n# Part 1: Import data\n\n## Import the dataset and remove the duplicates\n\nImport the dataset from the directory of: \\~/Data Input/Preprocessing\ndata/Preprocessing data.csv, assign the dataset as object of df:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf <- read.csv(\"~/Data Input/Preprocessing data/Preprocessing data.csv\")\n```\n:::\n\n\nRemove the duplicates with the function of distinct(), assign the\ndataset as df_01:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf_00 <- df |>\n  distinct() |>\n  rename(correct_PM10 = PM2, correct_PM2 = PM10) |>\n  mutate(PM10=correct_PM10, PM2=correct_PM2, PM10_rel=PM10, PM2_rel=PM2, ratio = PM2/PM10)\n```\n:::\n\n\n# Part 2: Bad and missing data\n\n############### Cleaning and Handling MISSING data\n\n1.  Mining bad data\n    a)  explore the spikes\n    b)  check the spikes against the other data whether to keep it or\n        delete it\n    c)  do iterative process with a) and b) for all data elements\n2.  Remove the bad data\n    a) replace with NA\n    b) replace with Median\n    c) replace with Mean\n3.  Data gap filling, carefully choosing the correct strategy\n    a) fill the data based on the seasonal/ daily variations/ and consider trend\n    b) fill the data with the median/mean or with the some relations\n    c) Search for the suitable... method\n\n############################################################################# \n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse) \nlibrary(ggplot2)\n\ndf <- read.csv(\"../Data/Preprocessing data.csv\")\n```\n:::\n\n\n## And remove duplicates\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf1 <- df %>% \n  distinct()\n```\n:::\n\n\n##### Converting types, renaming.\n\ndf1 \\<- df1 \\|\\> mutate(pm2_swap=PM10, pm10_swap=PM2, ratio =\npm2_swap/pm10_swap)\n\nglimpse(df1) df1$Date <- as.Date(df1$Date)\ndf1$Station.name <- as.factor(df1$Station.name)\n\n##### 1. Remove spikes\n\n## data range explore\n\nbreaks_pm10 \\<-\nc(min(df1$pm10_swap, na.rm = T), 0.001, 1, max(df1$pm10_swap, na.rm =\nT)) ggplot(df1, aes(pm10_swap)) + geom_histogram(breaks=breaks_pm10)\n\nbreaks_pm2 \\<-\nc(min(df1$pm2_swap, na.rm = T), 0.001, 1, max(df1$pm2_swap, na.rm = T))\nggplot(df1, aes(pm2_swap)) + geom_histogram(breaks=breaks_pm2)\n\n### spikes to NA, PM10 must be greater than PM2, and PM must be \\> 0\n\n## a. data range constrain 0-6\n\ndf2 \\<- df1 \\|\\> mutate(pm10_miss = replace(pm10_swap, pm10_swap \\> 7 \\|\npm10_swap == 0 , NA), pm2_miss = replace(pm2_swap, pm2_swap \\> 7 \\|\npm2_swap == 0, NA)) write_csv(df2, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\nplot(df2$pm10_miss, df2$pm2_miss) \\# df2 \\<- df1 \\|\\> \\#\nmutate(pm10_miss = replace(pm10_swap, pm10_swap \\> 6 \\| pm10_swap \\<\npm2_swap, NA), \\# pm2_miss = replace(pm2_swap, pm2_swap \\> 6 \\| pm2_swap\n\\> pm10_swap, NA), \\# ratio_miss = ifelse(pm10_miss \\>0,\npm2_miss/pm10_miss, NA)) \\# write_csv(df2, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\ndf2$Date < as.Date(df2$Date)\n\ndf2_UB \\<- df2 \\|\\> filter(Station.name == \"UB\") \\|\\> mutate(pm2_miss =\nreplace(pm2_swap, pm2_swap \\< 0.0011 \\| pm2_swap \\>30, NA), pm10_miss =\nreplace(pm10_swap, pm10_swap \\< 0.0011, NA)) write_csv(df2_UB, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_UB.csv\")\nplot(df2_UB$pm10_miss, df2_UB$pm2_miss)\n\ndf2_SSh \\<- df2 \\|\\> filter(Station.name == \"Sainshand\")\nwrite_csv(df2_UB, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_SSh.csv\")\nplot(df2_SSh$pm10_miss, df2_SSh$pm2_miss)\n\n###### Шуурсан бололтой\n\ndf2 \\|\\> filter(Station.name == \"Sainshand\" & Year ==2011 & Month ==6)\n\\|\\> ggplot(aes(Date, pm10_miss, size = WS, color=Visibility)) +\ngeom_point()\n\ndf2_DZ \\<- df2 \\|\\> filter(Station.name == \"Dalanzadgad\") \\|\\>\nmutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\|\npm2_swap == 0, NA)) write_csv(df2_DZ, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_DZ.csv\")\nplot(df2_DZ$pm10_miss, df2_DZ$pm2_miss)\n\ndf2 \\|\\> filter(Station.name == \"Dalanzadgad\") \\|\\> mutate(pm2_miss =\nreplace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA)) \\|\\>\nggplot(aes(pm10_miss, pm2_miss, size = WS)) + geom_point() +\nfacet_wrap(\\~Year)\n\n#### Zamyn uud\n\ndf2_ZU \\<- df2 \\|\\> filter(Station.name == \"Zamynuud\" ) \\|\\>\nmutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\|\npm2_swap == 0, NA), pm10_miss = replace(pm10_swap, Year \\> 2016 &\npm10_swap \\> 0.5 \\| Year \\> 2017, NA)) write_csv(df2_ZU, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_ZU.csv\")\nplot(df2_ZU$pm10_miss, df2_ZU$pm2_miss)\n\ndf2 \\|\\> filter(Station.name == \"Zamynuud\") \\|\\> mutate(pm2_miss =\nreplace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA),\npm10_miss = replace(pm10_swap, Year \\> 2016 & pm10_swap \\> 0.5\\| Year \\>\n2017, NA)) \\|\\> ggplot(aes(pm2_miss, pm10_miss, size = WS)) +\ngeom_point() + facet_wrap(\\~Year)\n\nbreaks_ratio \\<-\nc(min(df2$ratio_miss, na.rm = T), 0, 1, max(df2$ratio_miss, na.rm = T))\nsummary(breaks_ratio)\n\n######################## \n\n##################### \n\n###### df2 is nice. Now I can work with.\n\n######. Харин одоо data gap filling хийх үү? ######. Handling missing\ndata \\############################### \\###############################\n\\######## Convert into log\n\ndf2_log \\<- df1 \\|\\> mutate(pm10_log =\nlog(pm10_swap+0.0000000000000000001), pm2_log = log(pm2_swap +\n0.00000001), WS_log = log1p(WS))\n\ndf2_log \\<- df2_log \\|\\> mutate(pm10_miss_log = replace(pm10_log,\npm10_swap \\> 6 \\| pm10_swap \\< pm2_swap \\| pm10_swap == 0, NA),\npm2_miss_log = replace(pm2_log, pm2_swap \\> 6 \\| pm2_swap \\> pm10_swap\n\\|pm2_swap == 0 , NA)) write_csv(df2_log, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\nplot(density(df2_log$WS_log, na.rm=TRUE))\nplot(density(df1$pm10_swap, na.rm=TRUE))\nplot(df2_b$pm10_swap, df2_b$pm10_normal_dist)\n\nwrite_csv(df2_01, file =\n\"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_01.csv\")\n\nlog(0.04)\n\nlog1p(0) log\n\nplot(df2$pm10_miss, df2$pm2_miss)\n\n###### Check 0\n\ndf0 \\<- df2 \\|\\> filter(pm2_miss == 0 \\| pm10_miss == 0)\n\nplot(df2$ratio_miss, df2$ratio_adj)\n\n###### \n\n####. Dalanzad 2012 оны 6 сараас 7 сарын эхэн хүртэл PM10\\<PM2; солих\n\\######## df2 \\|\\> filter( Station.name == \"Sainshand\" & Year==2011 &\nMonth ==6) \\|\\> ggplot(aes(x= Date, y= pm10_miss, size = WS)) +\ngeom_point() + ylim(0,0.7) facet_wrap(\\~Month)\n\n#### \n\nggplot(df2, aes(x= Date, y= WS, color = WS)) + geom_point() +\n#ylim(0,10000) + facet_wrap(\\~Station.name)\n\nggplot(df0, aes(x= WS, y= ratio_miss, color = factor(Year))) +\ngeom_point() + ylim(0,3) + facet_wrap(\\~Station.name) \\####\n\nggplot(df2, aes(x= Date, y= pm10_miss, color = WS)) + geom_point() +\nfacet_wrap(\\~Station.name)\n\nplot(df1$pm2_adj, df1$pm10_adj) ggplot(df1, aes(pm2_adj, pm10_adj,\ncolor=Station.name, size=WS)) + geom_point()\n\nggplot(df1, aes(pm2_miss, pm10_miss, color=Station.name, size=WS)) +\ngeom_point()\n\n################################# \n\n################### Not used pieces\n\n### if PM2\\>PM10 , swap ------ NOT in this case\n\ndf_dal \\<- df2 \\|\\> filter(Station.name == \"Dalanzadgad\" & Year == 2011)\n\\|\\> transform(pm10_adj = pmax(pm2_miss, pm10_miss), pm2_adj =\npmin(pm2_miss, pm10_miss)) \\|\\> mutate(ratio_adj = pm2_adj/pm10_adj)\n\ndf_dal \\<- df2 \\|\\> transform(pm10_adj = pmax(pm2_miss, pm10_miss),\npm2_adj = pmin(pm2_miss, pm10_miss)) \\|\\> mutate(ratio_adj =\npm2_adj/pm10_adj)\n\nd \\<- df_dal \\|\\> filter(pm10_adj != pm10_miss \\| pm2_adj != pm2_miss)\n\n## Remove 0 measurements. Looks like no data, or malfunction.\n\narrange(PM10)\n\ndf1\\[1:87840, 6\\]\\[df1\\[1:87840, 6\\] == 0\\] \\<- NA\n\ndf1 \\<- df1 %\\>% distinct() \\|\\> arrange(PM2) df1\\[1:35460,\n5\\]\\[df1\\[1:35460, 5\\] == 0\\] \\<- NA \\# Part 3: Fill the missing data\n\n## Fill the missing data\n\nMethod 1. Fill the gap Method 2. Relationship equation Method 3. Look-up\ntable\n\n## Save dataset in folder: 02_data_tidy\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "02_dataAnalyze_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}