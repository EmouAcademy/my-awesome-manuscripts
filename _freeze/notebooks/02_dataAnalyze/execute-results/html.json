{
  "hash": "649817aad3d64428b9d5fc70349759ee",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"02_dataAnalyze\"\nauthor: \"Munkhtsetseg\"\n---\n\n\nLibrary\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ggplot2)\n```\n:::\n\n# Part 1: Import data\n## Import the dataset and remove the duplicates\n\nImport the dataset from the directory of: \\~/Data Input/Preprocessing data/Preprocessing data.csv, assign the dataset as object of df:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf <- read.csv(\"~/Data Input/Preprocessing data/Preprocessing data.csv\")\n```\n:::\n\n\nRemove the duplicates with the function of distinct(), assign the dataset as df_01:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf_00 <- df |>\n  distinct() |>\n  rename(correct_PM10 = PM2, correct_PM2 = PM10) |>\n  mutate(PM10=correct_PM10, PM2=correct_PM2, PM10_rel=PM10, PM2_rel=PM2, ratio = PM2/PM10)\n```\n:::\n\n\n# Part 2: Bad and missing data\n############### Cleaning and Handling MISSING data #########################\n# I. Mining bad data\n# a) explore the spikes\n# b) check the spikes against the other data whether to keep it or delete it\n# c) do iterative process with a) and b) for all data elements\n# II. Remove the bad data\n# a) replace with NA\n# b) replace with Median\n# c) replace with Mean\n# III. Data gap filling, carefully choosing the correct strategy\n# a) fill the data based on the seasonal/ daily variations/ and consider trend\n# b) fill the data with the median/mean or with the some relations\n# c) Search for the suitable... method\n#############################################################################\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nsetwd(\"~/2 Data Processing\")\ndf <- read.csv(\"~/Data Input/Preprocessing data/Preprocessing data.csv\")\n\n#Data$Station.name <- as.factor(Data$Station.name)\n#view(Data)\n\n## And remove duplicates\ndf1 <- df %>%\n  distinct()\n\n\n##### Converting types, renaming.\ndf1 <-  df1 |>\n  mutate(pm2_swap=PM10, pm10_swap=PM2, ratio = pm2_swap/pm10_swap)\n\nglimpse(df1)\ndf1$Date <- as.Date(df1$Date)\ndf1$Station.name <- as.factor(df1$Station.name) \n\n\n##### 1. Remove spikes\n##  data range explore\nbreaks_pm10 <- c(min(df1$pm10_swap, na.rm = T), 0.001, 1, max(df1$pm10_swap, na.rm = T))\nggplot(df1, aes(pm10_swap)) + \n  geom_histogram(breaks=breaks_pm10)\n\nbreaks_pm2 <- c(min(df1$pm2_swap, na.rm = T), 0.001, 1, max(df1$pm2_swap, na.rm = T))\nggplot(df1, aes(pm2_swap)) + \n  geom_histogram(breaks=breaks_pm2)\n\n\n### spikes to NA, PM10 must be greater than PM2, and PM must be > 0\n## a. data range constrain 0-6\ndf2 <- df1 |>\n  mutate(pm10_miss = replace(pm10_swap, pm10_swap > 7 | pm10_swap == 0 , NA), \n         pm2_miss = replace(pm2_swap, pm2_swap > 7 | pm2_swap == 0, NA))\nwrite_csv(df2, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\nplot(df2$pm10_miss, df2$pm2_miss)\n# df2 <- df1 |>\n#  mutate(pm10_miss = replace(pm10_swap, pm10_swap > 6 | pm10_swap < pm2_swap, NA), \n#         pm2_miss = replace(pm2_swap, pm2_swap > 6 | pm2_swap > pm10_swap, NA),\n#         ratio_miss = ifelse(pm10_miss >0, pm2_miss/pm10_miss, NA))\n# write_csv(df2, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\ndf2$Date < as.Date(df2$Date)\n\ndf2_UB <- df2 |>\n  filter(Station.name == \"UB\") |>\n  mutate(pm2_miss = replace(pm2_swap, pm2_swap < 0.0011 | pm2_swap >30, NA),\n         pm10_miss = replace(pm10_swap, pm10_swap < 0.0011, NA))\nwrite_csv(df2_UB, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_UB.csv\")\nplot(df2_UB$pm10_miss, df2_UB$pm2_miss)\n\ndf2_SSh <- df2 |>\n  filter(Station.name == \"Sainshand\")\nwrite_csv(df2_UB, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_SSh.csv\")\nplot(df2_SSh$pm10_miss, df2_SSh$pm2_miss)\n\n###### Шуурсан бололтой\ndf2 |>\n  filter(Station.name == \"Sainshand\" & Year ==2011 & Month ==6) |>\n  ggplot(aes(Date, pm10_miss, size = WS, color=Visibility)) +\n  geom_point()\n\n\n\ndf2_DZ <- df2 |>\n  filter(Station.name == \"Dalanzadgad\") |>\n  mutate(pm2_miss = replace(pm2_swap, pm2_swap > pm10_swap*3.5 | pm2_swap == 0, NA))\nwrite_csv(df2_DZ, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_DZ.csv\")\nplot(df2_DZ$pm10_miss, df2_DZ$pm2_miss)\n\ndf2 |>\n  filter(Station.name == \"Dalanzadgad\") |>\n  mutate(pm2_miss = replace(pm2_swap, pm2_swap > pm10_swap*3.5 | pm2_swap == 0, NA)) |>\n  ggplot(aes(pm10_miss, pm2_miss, size = WS)) +\n  geom_point() +\n  facet_wrap(~Year)\n\n\n#### Zamyn uud\ndf2_ZU <- df2 |>\nfilter(Station.name == \"Zamynuud\" ) |>\n  mutate(pm2_miss = replace(pm2_swap, pm2_swap > pm10_swap*3.5 | pm2_swap == 0, NA),\n         pm10_miss = replace(pm10_swap, Year > 2016 & pm10_swap > 0.5 | Year > 2017, NA))\nwrite_csv(df2_ZU, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_ZU.csv\")\nplot(df2_ZU$pm10_miss, df2_ZU$pm2_miss)\n\n  \n  df2 |>\n  filter(Station.name == \"Zamynuud\") |>\n  mutate(pm2_miss = replace(pm2_swap, pm2_swap > pm10_swap*3.5 | pm2_swap == 0, NA),\n         pm10_miss = replace(pm10_swap, Year > 2016 & pm10_swap > 0.5| Year > 2017, NA)) |>\n  ggplot(aes(pm2_miss, pm10_miss, size = WS)) +\n  geom_point() +\n    facet_wrap(~Year)\n\n\n\n\nbreaks_ratio <- c(min(df2$ratio_miss, na.rm = T), 0, 1, max(df2$ratio_miss, na.rm = T))\nsummary(breaks_ratio)\n\n########################\n#####################\n######    df2 is nice. Now I can work with.\n######.   Харин одоо data gap filling хийх үү?\n######.   Handling missing data\n###############################\n###############################\n######## Convert into log\n\ndf2_log <- df1 |>\n  mutate(pm10_log = log(pm10_swap+0.0000000000000000001),\n         pm2_log = log(pm2_swap + 0.00000001),\n         WS_log = log1p(WS))\n\ndf2_log <- df2_log |>\nmutate(pm10_miss_log = replace(pm10_log, pm10_swap > 6 | pm10_swap < pm2_swap | pm10_swap == 0, NA), \n       pm2_miss_log = replace(pm2_log, pm2_swap > 6 | pm2_swap > pm10_swap |pm2_swap == 0 , NA))\nwrite_csv(df2_log, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv\")\n\n\nplot(density(df2_log$WS_log, na.rm=TRUE)) \nplot(density(df1$pm10_swap, na.rm=TRUE))\nplot(df2_b$pm10_swap, df2_b$pm10_normal_dist)\n\nwrite_csv(df2_01, file = \"/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_01.csv\")\n\n\nlog(0.04)\n\nlog1p(0)\nlog\n\n\n\nplot(df2$pm10_miss, df2$pm2_miss)        \n\n###### Check 0\ndf0 <- df2 |>\n  filter(pm2_miss == 0 | pm10_miss == 0)\n\nplot(df2$ratio_miss, df2$ratio_adj)\n\n######\n####.   Dalanzad 2012 оны 6 сараас 7 сарын эхэн хүртэл PM10<PM2; солих\n########\ndf2 |>\n  filter( Station.name == \"Sainshand\" & Year==2011 & Month ==6) |>\n  ggplot(aes(x= Date, y= pm10_miss, \n             size = WS)) + \n  geom_point() +\n  ylim(0,0.7)\n  facet_wrap(~Month)\n\n####\nggplot(df2, aes(x= Date, y= WS, \n           color = WS)) + \n  geom_point() +\n#ylim(0,10000) +\n  facet_wrap(~Station.name)\n\nggplot(df0, aes(x= WS, y= ratio_miss, \n                color = factor(Year))) + \n  geom_point() +\n ylim(0,3) +\n  facet_wrap(~Station.name)\n####\n\nggplot(df2, aes(x= Date, y= pm10_miss, \n                color = WS)) + \n  geom_point() +\n  facet_wrap(~Station.name)\n\n\nplot(df1$pm2_adj, df1$pm10_adj)\nggplot(df1, aes(pm2_adj, pm10_adj, color=Station.name, size=WS)) + \n  geom_point()\n\nggplot(df1, aes(pm2_miss, pm10_miss, color=Station.name, size=WS)) + \n  geom_point()\n\n\n\n\n#################################\n################### Not used pieces\n### if PM2>PM10 , swap ------ NOT in this case\ndf_dal <- df2 |>\n  filter(Station.name == \"Dalanzadgad\" & Year == 2011) |>\n  transform(pm10_adj = pmax(pm2_miss, pm10_miss), \n            pm2_adj = pmin(pm2_miss, pm10_miss)) |>\n  mutate(ratio_adj = pm2_adj/pm10_adj)\n\ndf_dal <- df2 |>\n  transform(pm10_adj = pmax(pm2_miss, pm10_miss), \n            pm2_adj = pmin(pm2_miss, pm10_miss)) |>\n  mutate(ratio_adj = pm2_adj/pm10_adj)\n\nd <- df_dal |>\n  filter(pm10_adj != pm10_miss | pm2_adj != pm2_miss)\n\n\n\n## Remove 0 measurements. Looks like no data, or malfunction. \narrange(PM10) \n\ndf1[1:87840, 6][df1[1:87840, 6] == 0] <- NA\n\n\ndf1 <- df1 %>%\n  distinct() |>\n  arrange(PM2) \ndf1[1:35460, 5][df1[1:35460, 5] == 0] <- NA\n# Part 3: Fill the missing data\n\n## Fill the missing data\n\nMethod 1. Fill the gap Method 2. Relationship equation Method 3. Look-up table\n\n## Save dataset in folder: 02_data_tidy\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "02_dataAnalyze_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}