{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_dataAnalyze\n",
    "\n",
    "Munkhtsetseg\n",
    "\n",
    "Library"
   ],
   "id": "4e63edde-2736-48ca-aa6e-eed5453f6229"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.5\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n",
      "✔ purrr     1.0.2     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n"
   ],
   "id": "b31498c1-2769-48dc-83cb-55d3a4cc9e68"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Import data\n",
    "\n",
    "## Import the dataset and remove the duplicates\n",
    "\n",
    "Import the dataset from the directory of: ~/Data Input/Preprocessing data/Preprocessing data.csv, assign the dataset as object of df:"
   ],
   "id": "9e2deb4e-83a5-449e-81f5-9519dd6c8f0b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- read.csv(\"~/Data Input/Preprocessing data/Preprocessing data.csv\")\n"
   ],
   "id": "279f4f0b-b7dd-4449-b025-595a1fa33c52"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicates with the function of distinct(), assign the dataset as df_01:"
   ],
   "id": "68775b9e-b7a7-4c5b-989c-0b49473c79fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00 <- df |>\n",
    "  distinct() |>\n",
    "  rename(correct_PM10 = PM2, correct_PM2 = PM10) |>\n",
    "  mutate(PM10=correct_PM10, PM2=correct_PM2, PM10_rel=PM10, PM2_rel=PM2, ratio = PM2/PM10)\n"
   ],
   "id": "f60afa00-28c5-42c4-8fbe-fd6ed58f984d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Bad and missing data\n",
    "\n",
    "############### Cleaning and Handling MISSING data\n",
    "\n",
    "1.  Mining bad data\n",
    "    1.  explore the spikes\n",
    "    2.  check the spikes against the other data whether to keep it or delete it\n",
    "    3.  do iterative process with a) and b) for all data elements\n",
    "2.  Remove the bad data\n",
    "    1.  replace with NA\n",
    "    2.  replace with Median\n",
    "    3.  replace with Mean\n",
    "3.  Data gap filling, carefully choosing the correct strategy\n",
    "    1.  fill the data based on the seasonal/ daily variations/ and consider trend\n",
    "    2.  fill the data with the median/mean or with the some relations\n",
    "    3.  Search for the suitable… method\n",
    "\n",
    "#############################################################################"
   ],
   "id": "fbd0f447-6c9a-43ba-8ad3-500fdefd57d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse) \n",
    "library(ggplot2)\n",
    "\n",
    "df <- read.csv(\"../Data/Preprocessing data.csv\")\n"
   ],
   "id": "454ceb2b-5b8d-44f7-bf72-dbb4925f9511"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And remove duplicates"
   ],
   "id": "c9ad3d33-da9b-4542-8c65-0878144af92f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 <- df %>% \n",
    "  distinct()\n"
   ],
   "id": "8584026a-a661-4a9b-a6cd-b551ff6ed9da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting types, renaming.\n",
    "\n",
    "df1 \\<- df1 \\|\\> mutate(pm2_swap=PM10, pm10_swap=PM2, ratio = pm2_swap/pm10_swap)\n",
    "\n",
    "glimpse(df1) df1$Date <- as.Date(df1$Date) df1$Station.name <- as.factor(df1$Station.name)\n",
    "\n",
    "##### 1. Remove spikes\n",
    "\n",
    "## data range explore\n",
    "\n",
    "breaks_pm10 \\<- c(min(df1$pm10_swap, na.rm = T), 0.001, 1, max(df1$pm10_swap, na.rm = T)) ggplot(df1, aes(pm10_swap)) + geom_histogram(breaks=breaks_pm10)\n",
    "\n",
    "breaks_pm2 \\<- c(min(df1$pm2_swap, na.rm = T), 0.001, 1, max(df1$pm2_swap, na.rm = T)) ggplot(df1, aes(pm2_swap)) + geom_histogram(breaks=breaks_pm2)\n",
    "\n",
    "### spikes to NA, PM10 must be greater than PM2, and PM must be \\> 0\n",
    "\n",
    "## a. data range constrain 0-6\n",
    "\n",
    "df2 \\<- df1 \\|\\> mutate(pm10_miss = replace(pm10_swap, pm10_swap \\> 7 \\| pm10_swap == 0 , NA), pm2_miss = replace(pm2_swap, pm2_swap \\> 7 \\| pm2_swap == 0, NA)) write_csv(df2, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv”)\n",
    "\n",
    "plot(df2$pm10_miss, df2$pm2_miss) \\# df2 \\<- df1 \\|\\> \\# mutate(pm10_miss = replace(pm10_swap, pm10_swap \\> 6 \\| pm10_swap \\< pm2_swap, NA), \\# pm2_miss = replace(pm2_swap, pm2_swap \\> 6 \\| pm2_swap \\> pm10_swap, NA), \\# ratio_miss = ifelse(pm10_miss \\>0, pm2_miss/pm10_miss, NA)) \\# write_csv(df2, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv”)\n",
    "\n",
    "df2$Date < as.Date(df2$Date)\n",
    "\n",
    "df2_UB \\<- df2 \\|\\> filter(Station.name == “UB”) \\|\\> mutate(pm2_miss = replace(pm2_swap, pm2_swap \\< 0.0011 \\| pm2_swap \\>30, NA), pm10_miss = replace(pm10_swap, pm10_swap \\< 0.0011, NA)) write_csv(df2_UB, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_UB.csv”) plot(df2_UB$pm10_miss, df2_UB$pm2_miss)\n",
    "\n",
    "df2_SSh \\<- df2 \\|\\> filter(Station.name == “Sainshand”) write_csv(df2_UB, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_SSh.csv”) plot(df2_SSh$pm10_miss, df2_SSh$pm2_miss)\n",
    "\n",
    "###### Шуурсан бололтой\n",
    "\n",
    "df2 \\|\\> filter(Station.name == “Sainshand” & Year ==2011 & Month ==6) \\|\\> ggplot(aes(Date, pm10_miss, size = WS, color=Visibility)) + geom_point()\n",
    "\n",
    "df2_DZ \\<- df2 \\|\\> filter(Station.name == “Dalanzadgad”) \\|\\> mutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA)) write_csv(df2_DZ, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_DZ.csv”) plot(df2_DZ$pm10_miss, df2_DZ$pm2_miss)\n",
    "\n",
    "df2 \\|\\> filter(Station.name == “Dalanzadgad”) \\|\\> mutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA)) \\|\\> ggplot(aes(pm10_miss, pm2_miss, size = WS)) + geom_point() + facet_wrap(~Year)\n",
    "\n",
    "#### Zamyn uud\n",
    "\n",
    "df2_ZU \\<- df2 \\|\\> filter(Station.name == “Zamynuud” ) \\|\\> mutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA), pm10_miss = replace(pm10_swap, Year \\> 2016 & pm10_swap \\> 0.5 \\| Year \\> 2017, NA)) write_csv(df2_ZU, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_ZU.csv”) plot(df2_ZU$pm10_miss, df2_ZU$pm2_miss)\n",
    "\n",
    "df2 \\|\\> filter(Station.name == “Zamynuud”) \\|\\> mutate(pm2_miss = replace(pm2_swap, pm2_swap \\> pm10_swap\\*3.5 \\| pm2_swap == 0, NA), pm10_miss = replace(pm10_swap, Year \\> 2016 & pm10_swap \\> 0.5\\| Year \\> 2017, NA)) \\|\\> ggplot(aes(pm2_miss, pm10_miss, size = WS)) + geom_point() + facet_wrap(~Year)\n",
    "\n",
    "breaks_ratio \\<- c(min(df2$ratio_miss, na.rm = T), 0, 1, max(df2$ratio_miss, na.rm = T)) summary(breaks_ratio)\n",
    "\n",
    "######################## \n",
    "\n",
    "##################### \n",
    "\n",
    "###### df2 is nice. Now I can work with.\n",
    "\n",
    "######. Харин одоо data gap filling хийх үү? ######. Handling missing data \\############################### \\############################### \\######## Convert into log\n",
    "\n",
    "df2_log \\<- df1 \\|\\> mutate(pm10_log = log(pm10_swap+0.0000000000000000001), pm2_log = log(pm2_swap + 0.00000001), WS_log = log1p(WS))\n",
    "\n",
    "df2_log \\<- df2_log \\|\\> mutate(pm10_miss_log = replace(pm10_log, pm10_swap \\> 6 \\| pm10_swap \\< pm2_swap \\| pm10_swap == 0, NA), pm2_miss_log = replace(pm2_log, pm2_swap \\> 6 \\| pm2_swap \\> pm10_swap \\|pm2_swap == 0 , NA)) write_csv(df2_log, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2.csv”)\n",
    "\n",
    "plot(density(df2_log$WS_log, na.rm=TRUE))\n",
    "plot(density(df1$pm10_swap, na.rm=TRUE)) plot(df2_b$pm10_swap, df2_b$pm10_normal_dist)\n",
    "\n",
    "write_csv(df2_01, file = “/Users/munkhtsetseg/WORK/Research/Data/02_data_tidy/clean_df2_01.csv”)\n",
    "\n",
    "log(0.04)\n",
    "\n",
    "log1p(0) log\n",
    "\n",
    "plot(df2$pm10_miss, df2$pm2_miss)\n",
    "\n",
    "###### Check 0\n",
    "\n",
    "df0 \\<- df2 \\|\\> filter(pm2_miss == 0 \\| pm10_miss == 0)\n",
    "\n",
    "plot(df2$ratio_miss, df2$ratio_adj)\n",
    "\n",
    "###### \n",
    "\n",
    "####. Dalanzad 2012 оны 6 сараас 7 сарын эхэн хүртэл PM10\\<PM2; солих \\######## df2 \\|\\> filter( Station.name == “Sainshand” & Year==2011 & Month ==6) \\|\\> ggplot(aes(x= Date, y= pm10_miss, size = WS)) + geom_point() + ylim(0,0.7) facet_wrap(~Month)\n",
    "\n",
    "#### \n",
    "\n",
    "ggplot(df2, aes(x= Date, y= WS, color = WS)) + geom_point() + #ylim(0,10000) + facet_wrap(~Station.name)\n",
    "\n",
    "ggplot(df0, aes(x= WS, y= ratio_miss, color = factor(Year))) + geom_point() + ylim(0,3) + facet_wrap(~Station.name) \\####\n",
    "\n",
    "ggplot(df2, aes(x= Date, y= pm10_miss, color = WS)) + geom_point() + facet_wrap(~Station.name)\n",
    "\n",
    "plot(df1$pm2_adj, df1$pm10_adj) ggplot(df1, aes(pm2_adj, pm10_adj, color=Station.name, size=WS)) + geom_point()\n",
    "\n",
    "ggplot(df1, aes(pm2_miss, pm10_miss, color=Station.name, size=WS)) + geom_point()\n",
    "\n",
    "################################# \n",
    "\n",
    "################### Not used pieces\n",
    "\n",
    "### if PM2\\>PM10 , swap —— NOT in this case\n",
    "\n",
    "df_dal \\<- df2 \\|\\> filter(Station.name == “Dalanzadgad” & Year == 2011) \\|\\> transform(pm10_adj = pmax(pm2_miss, pm10_miss), pm2_adj = pmin(pm2_miss, pm10_miss)) \\|\\> mutate(ratio_adj = pm2_adj/pm10_adj)\n",
    "\n",
    "df_dal \\<- df2 \\|\\> transform(pm10_adj = pmax(pm2_miss, pm10_miss), pm2_adj = pmin(pm2_miss, pm10_miss)) \\|\\> mutate(ratio_adj = pm2_adj/pm10_adj)\n",
    "\n",
    "d \\<- df_dal \\|\\> filter(pm10_adj != pm10_miss \\| pm2_adj != pm2_miss)\n",
    "\n",
    "## Remove 0 measurements. Looks like no data, or malfunction.\n",
    "\n",
    "arrange(PM10)\n",
    "\n",
    "df1\\[1:87840, 6\\]\\[df1\\[1:87840, 6\\] == 0\\] \\<- NA\n",
    "\n",
    "df1 \\<- df1 %\\>% distinct() \\|\\> arrange(PM2) df1\\[1:35460, 5\\]\\[df1\\[1:35460, 5\\] == 0\\] \\<- NA \\# Part 3: Fill the missing data\n",
    "\n",
    "## Fill the missing data\n",
    "\n",
    "Method 1. Fill the gap Method 2. Relationship equation Method 3. Look-up table\n",
    "\n",
    "## Save dataset in folder: 02_data_tidy"
   ],
   "id": "0f8b1c9d-5b70-40ec-827b-5c2ad86ba71c"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
